---
title: "Personal Loan Analysis: Project 2 Stats 2 DataScience@SMU Summer 2022"
author: "Laura Ahumada, Erin McClure-Price, Duy Nguyen"
date: "07/16/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r, warning=F, message=F}
library(tidyverse)
# library(psych)          # describe()
library(DataExplorer)     # plot_missing() | drop_columns()
library(caret)            # nearZeroVar() | knnreg()
# library(inspectdf)      # inspect_cat() | show_plots()
# library(ggstance)       # geom_boxploth()
# library(corrplot)       # corrplot() | cor()
# library(ggpubr)         # ggscatter()
library(MASS)             # stepAIC()
library(regclass)         # vif()
# library(leaps)          # regsubsets()
library(ggplot2)          # ggplot()
library(glmtoolbox)       # hltest()
# library(purrr)          # map()
library(GGally)           # ggcorr() | ggpairs()
library(lindia)           # gg_cooksd() | gg_scalelocation
library(gridExtra)        # grid.arrange
# library(FNN)            # knn.reg()
# library(Metrics)        # mse()
library(glmnet)           # cv.glmnet()
library(ROCR)             # prediction() | performance()
library(stats)            # logLik()
library(MLmetrics)        # LogLoss()
#################CLUSTERS#################
library(mvtnorm)
library(RColorBrewer)
library(pheatmap)
library(cluster)

```

## Import Data
```{r}
getwd()
df = read.csv("Bank_Personal_Loan_Modelling.csv")

```

## EDA
```{r}
str(df)

# Identification Columns (ID and ZIP.Code)
df = df[-c(1,5)]
str(df)

# Naturally Factor Variables
factor_vars = c("Family", "Education", "Personal.Loan", 
                "Securities.Account", "CD.Account", "Online", "CreditCard")
df[factor_vars] = lapply(df[factor_vars], as.factor)
str(df)

# missing values
plot_missing(df)

# near zero variance
nearZeroVar(df, names = TRUE)
df = df[-c(nearZeroVar(df))]
str(df)

# multicollinearity
ggcorr(df, label = T)
## Age and Experience have correlation of 1
ggplot( df, aes(Experience, Age)) + geom_point()
ggplot(df, aes(Experience/Age)) + geom_histogram()
df = df %>% mutate(Experience2 = Experience/Age)
df = df[-c(1,2)] # getting rid of Age and Experience
str(df)
ggcorr(df, label = T)
```

```{r, message=F}
# pairs plots
#newAuto$mpg<-factor(ifelse(Auto$mpg>median(Auto$mpg),"High","Low"),levels=c("Low","High"))   # used for numeric outcome into categorical outcome (using median)
              # kept for future reference
levels(df$Personal.Loan) = c("No", "Yes")
ggpairs(df, aes(colour = Personal.Loan))

## Using the trick of already knowing what my stepwise logistic regression model consists of in terms of coefficients (which are Income, Family, CCAvg, Education, Securities.Account, CD.Account, Online, and CreditCard) I can pretend to say that the following variables can be considered in our model for Objective 1 to predict whether if a customer will accept a personal loan offer or not.

## We can see that, for variables with multiple levels, the levels with even a slight change compared to the reference level (1st level) are found as significant to our stepwise logistic regression model.

# This determines green is yes.
plot(df$Personal.Loan, col = c("blue", "green")) 
par(mfrow=c(2,3))
plot(Personal.Loan ~ ., data = df, col=c("green", "blue"))

```

## EDA: Heatmaps (Unit 13)
```{r}

```

## EDA: Cluster Analysis (Unit 13)
```{r}

```

## Train Test Split
```{r}
set.seed(123)

split = sample(nrow(df), nrow(df)*0.7)

train = df[split,]
test = df[-split,]

```

# Objective 1: Logistic Regression Model
```{r}
premodel = glm(Personal.Loan ~ ., data = train, family = "binomial")

# feature selection - stepwise
stepAIC(premodel, direction = "both")

model1 = glm(formula = Personal.Loan ~ Income + Family + CCAvg + Education + 
    Securities.Account + CD.Account + Online + CreditCard, family = "binomial", 
    data = train)

```

### Hypothesis Testing
```{r}
summary(model1)

# As the p-values of all variables used in model1, aside from Family2, are all less than 0.05, none of them are insignificant in our logistic regression model.
```

### Criterion
```{r}
-2*logLik(model1)[1] # -2LL = 794.0738
AIC(model1)          #  AIC = 818.07
BIC(model1)          #  BIC = 892
```

### Verify Predictions Manually
```{r}
# Holding the upcoming predictions accountable
prop.table(table(df$Personal.Loan))
prop.table(table(train$Personal.Loan))
prop.table(table(test$Personal.Loan))

# This means that, 
# it is preferred that our predictions are 90% no loan and 10% yes loan.

# The general idea is, for a bank problem like this where we are trying to find profit from the highest number of customers who will accept a personal loan offer as we can, we want to have an as-low-as-possible chance of predicting customers saying no but they actually do want to say yes because, not calling an interested customer will cost us valuable profits. However, calling a disinterested customer will not hurt that much where they will simply assume that it's a cold call. Unless our decisions mean that the bank can forcibly and automatically give a customer a loan despite them not being interested in a loan, or rather a more realistic example like using software to determine a patient to have cancer even though they do not, and that patient will wastefully go through a surgery process, like an actionable decision from our predictions, we should be fine with a low specificity (with the other proportion of low specificity meaning a high chance of predicting yes to people saying no, which is perfectly OK and can be overlooked).

pred.step = predict(model1, test)

step.cutoff = 0.7
class.step = as.factor(if_else(pred.step < step.cutoff, "No", "Yes"))
#pred = as.factor(if_else(pred < 0.3, 0, 1))
prop.table(table(class.step))

# Confusion Matrix
confusionMatrix(class.step, test$Personal.Loan)
```

### Assumptions via PLOTS
```{r}
par(mfrow = c(1, 2))
#Cook's Distance Plot
plot(model1, 4)

#Standardized Residuals vs Leverage
plot(model1, 5)
par(mfrow = c(1, 1))

```

### Interpretations and Confidence Intervals
```{r}
# interpret as log odds & confidence intervals
format(exp(cbind("Odds Ratio" = coef(model1), 
                 confint.default(model1, level = 0.95))),
       scientific = F)

# Holding all other variables constant, 
### an increase of $1,000 in a customer's income is associated with an increase of 6.58871% in the odds of them accepting a personal loan offer.
### ...
### customers with a family size of 3 have a 5.83 times the odds of those who don't of accepting a personal loan offer.
### customers with a securities account have a .49 times the odds of those who don't of accepting a personal loan offer.
### ...

# vifs
VIF(model1)
## all variables seem to be valid since none are above 5 or 10

```

## Objective 1: LASSO Penalized Logistic Regression Model
```{r}
dat.train.x = model.matrix(Personal.Loan ~ Income + Family + CCAvg + Education + Securities.Account + CD.Account + Online + CreditCard + Experience2, train)
dat.train.y = train$Personal.Loan

cvfit = cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")
# CV misclassification error rate is little below .10
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

# Optimal penalty
cvfit$lambda.min

# For final model predictions go ahead and refit lasso using entire data set
LASSOmodel = glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)

# Predict
dat.test.x = model.matrix(Personal.Loan ~ Income + Family + CCAvg + Education + Securities.Account + CD.Account + Online + CreditCard + Experience2, test)
fit.pred.lasso = predict(LASSOmodel, newx = dat.test.x, type = "response")

LASSO.cutoff = 0.44
class.lasso = as.factor(if_else(fit.pred.lasso < LASSO.cutoff, "No", "Yes"))

# Confusion Matrix for Lasso
conf.lasso = table(class.lasso, test$Personal.Loan)
conf.lasso

# Accuracy of LASSO
sum(diag(conf.lasso))/sum(conf.lasso)

# Sensitivity & Specificity of LASSO
cm = confusionMatrix(class.lasso, test$Personal.Loan)
cm$byClass

# Criterion of glmnet
tLL = LASSOmodel$nulldev - deviance(LASSOmodel)
k = LASSOmodel$df
n = LASSOmodel$nobs

tLL                             # -2LL = 1351.948
-1*(-tLL+2*k+2*k*(k+1)/(n-k-1)) #  AIC = 1329.872
-1*(log(n)*k - tLL)             #  BIC = 1262.182


```

## Objective 1: Erin's Model based on intuition
```{r}
mod4 = glm(formula = Personal.Loan ~ CreditCard + Family + CD.Account + Education + Income,
           family = "binomial", data = train)
summary(mod4)

pred.erin = predict(mod4, test, type = "response")

erin.cutoff = 0.55
class.erin = as.factor(if_else(pred.erin < erin.cutoff, "No", "Yes"))
prop.table(table(class.erin))
confusionMatrix(class.erin, test$Personal.Loan)

# Criterion
-2*logLik(mod4)[1] # -2LL = 818.8792
AIC(mod4)          #  AIC = 836.8792
BIC(mod4)          #  BIC = 892.3239

```

## Objective 1: Origin Model (Income Only)
```{r}
model_income = glm(formula = Personal.Loan ~ Income, family = "binomial", data = train)
summary(model_income)

pred.income = predict(model_income, test, type = "response")

income.cutoff = 0.3
class.income = as.factor(if_else(pred.income < income.cutoff, "No", "Yes"))
prop.table(table(class.income))
confusionMatrix(class.income, test$Personal.Loan)

# Criterion
-2*logLik(model_income)[1] # -2LL = 1407.45
AIC(model_income)          #  AIC = 1411.45
BIC(model_income)          #  BIC = 1423.771
```

### Comparing ROCR Curves
```{r}
# Stepwise
pred_prob = predict(model1, test, type = "response")
test_label = df[-split, "Personal.Loan"]
results.step = prediction(pred_prob, test_label)
roc.step = performance(results.step, measure = "tpr", x.measure = "fpr")

# LASSO
results.lasso = prediction(fit.pred.lasso,
                           test$Personal.Loan, 
                           label.ordering=c("No", "Yes"))
roc.lasso = performance(results.lasso, measure = "tpr", x.measure = "fpr")

# Erin's Intuition
results.erin = prediction(pred.erin, test_label)
roc.erin = performance(results.erin, measure = "tpr", x.measure = "fpr")

# Origin (Income Only)
results.income = prediction(pred.income, test_label)
roc.income = performance(results.income, measure = "tpr", x.measure = "fpr")

plot(roc.step, col = "red", xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.lasso, col = "green", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.erin, col = "blue", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.income, col = "pink", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
legend("bottomright", legend = c("Stepwise", "Lasso", "Erin", "Origin (Income Only)"), 
       col = c("red", "green","blue", "pink"), 
       lty=1, lwd=1)
#abline(a=0, b= 1)
#abline(a=1, b= -1)

# LASSO seems to be the better performing model according to the above plot.

```

# Objective 2: Adding Complexity
```{r}
model.poly.income2 = glm(formula = Personal.Loan ~ poly(Income, 2) + Family + CCAvg + Education + Securities.Account + CD.Account + Online + CreditCard, family = "binomial", data = train)
pred.poly.income2 = predict(model.poly.income2, test, type = "response")
poly.income2.cutoff = 0.55
class.poly.income2 = as.factor(if_else(pred.poly.income2 < poly.income2.cutoff, "No", "Yes"))
prop.table(table(class.poly.income2))
confusionMatrix(class.poly.income2, test$Personal.Loan)
results.poly.income2 = prediction(pred.poly.income2, test_label)
roc.poly.income2 = performance(results.poly.income2, measure = "tpr", x.measure = "fpr")

model.poly.income3 = glm(formula = Personal.Loan ~ poly(Income, 3) + Family + CCAvg + Education + Securities.Account + CD.Account + Online + CreditCard, family = "binomial", data = train)
pred.poly.income3 = predict(model.poly.income3, test, type = "response")
poly.income3.cutoff = 0.55
class.poly.income3 = as.factor(if_else(pred.poly.income3 < poly.income3.cutoff, "No", "Yes"))
prop.table(table(class.poly.income3))
confusionMatrix(class.poly.income3, test$Personal.Loan)
results.poly.income3 = prediction(pred.poly.income3, test_label)
roc.poly.income3 = performance(results.poly.income3, measure = "tpr", x.measure = "fpr")

model.poly.CCAvg2 = glm(formula = Personal.Loan ~ Income + Family + poly(CCAvg, 2) + Education + Securities.Account + CD.Account + Online + CreditCard, family = "binomial", data = train)
pred.poly.CCAvg2 = predict(model.poly.CCAvg2, test, type = "response")
poly.CCAvg2.cutoff = 0.55
class.poly.CCAvg2 = as.factor(if_else(pred.poly.CCAvg2 < poly.CCAvg2.cutoff, "No", "Yes"))
prop.table(table(class.poly.CCAvg2))
confusionMatrix(class.poly.CCAvg2, test$Personal.Loan)
results.poly.CCAvg2 = prediction(pred.poly.CCAvg2, test_label)
roc.poly.CCAvg2 = performance(results.poly.CCAvg2, measure = "tpr", x.measure = "fpr")

model.poly.CCAvg3 = glm(formula = Personal.Loan ~ Income + Family + poly(CCAvg, 3) + Education + Securities.Account + CD.Account + Online + CreditCard, family = "binomial", data = train)
pred.poly.CCAvg3 = predict(model.poly.CCAvg3, test, type = "response")
poly.CCAvg3.cutoff = 0.55
class.poly.CCAvg3 = as.factor(if_else(pred.poly.CCAvg3 < poly.CCAvg3.cutoff, "No", "Yes"))
prop.table(table(class.poly.CCAvg3))
confusionMatrix(class.poly.CCAvg3, test$Personal.Loan)
results.poly.CCAvg3 = prediction(pred.poly.CCAvg3, test_label)
roc.poly.CCAvg3 = performance(results.poly.CCAvg3, measure = "tpr", x.measure = "fpr")

model.poly.both2 = glm(formula = Personal.Loan ~ poly(Income, 2) + Family + poly(CCAvg, 2) + Education + Securities.Account + CD.Account + Online + CreditCard, family = "binomial", data = train)
pred.poly.both2 = predict(model.poly.both2, test, type = "response")
poly.both2.cutoff = 0.55
class.poly.both2 = as.factor(if_else(pred.poly.both2 < poly.both2.cutoff, "No", "Yes"))
prop.table(table(class.poly.both2))
confusionMatrix(class.poly.both2, test$Personal.Loan)
results.poly.both2 = prediction(pred.poly.both2, test_label)
roc.poly.both2 = performance(results.poly.both2, measure = "tpr", x.measure = "fpr")

model.poly.both3 = glm(formula = Personal.Loan ~ poly(Income, 3) + Family + poly(CCAvg, 3) + Education + Securities.Account + CD.Account + Online + CreditCard, family = "binomial", data = train)
pred.poly.both3 = predict(model.poly.both3, test, type = "response")
poly.both3.cutoff = 0.55
class.poly.both3 = as.factor(if_else(pred.poly.both3 < poly.both3.cutoff, "No", "Yes"))
prop.table(table(class.poly.both3))
confusionMatrix(class.poly.both3, test$Personal.Loan)
results.poly.both3 = prediction(pred.poly.both3, test_label)
roc.poly.both3 = performance(results.poly.both3, measure = "tpr", x.measure = "fpr")

confusionMatrix(class.poly.income2, test$Personal.Loan)$overall[1]
confusionMatrix(class.poly.income3, test$Personal.Loan)$overall[1]
confusionMatrix(class.poly.CCAvg2, test$Personal.Loan)$overall[1]
confusionMatrix(class.poly.CCAvg3, test$Personal.Loan)$overall[1]
confusionMatrix(class.poly.both2, test$Personal.Loan)$overall[1]
confusionMatrix(class.poly.both3, test$Personal.Loan)$overall[1]

plot(roc.lasso, col = "red", xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.income2, col = "green", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.income3, col = "blue", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.CCAvg2, col = "blueviolet", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.CCAvg3, col = "aquamarine", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.both2, col = "chartreuse", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.both3, col = "coral", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
legend("bottomright", legend = c("Stepwise", "polyincome2", "polyincome3", "polyCCAVg2", "polyCCAvg3", "polyboth2", "polyboth3"), 
       col = c("red", "green", "blue", "blueviolet", "aquamarine", "chartreuse", "coral"), 
       lty=1, lwd=1)

# Polynomial Income^3 seems to be the best performing model according to the above plot.

```

# Objective 2: LDA (continuous predictors only)
```{r}
# Find only continuous predictors
str(train)

# Setting up for PCA then LDA
LDA_train = select_if(train, is.numeric) %>% mutate(Personal.Loan = train$Personal.Loan)
str(LDA_train)
pairs(LDA_train)

# PCA
reduced = LDA_train[-c(4)]
pc.result<-prcomp(reduced,scale.=FALSE)
eigenvals<-(pc.result$sdev)^2
eigenvals
plot(1:3,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. 
Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:3,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
par(mfrow=c(1,1))

# The desired number of PCs looks to be 1, since 2 retains 0% of the total variation.

# Build Model
LDA.model = lda(Personal.Loan ~ ., LDA_train)
LDA.model

fit.p<-predict(LDA.model, newdata=test)
results.model<-prediction(fit.p$posterior[,2], test$Personal.Loan,label.ordering=c("No","Yes"))
roc.lda_= performance(results.model, measure = "tpr", x.measure = "fpr")

plot(roc.lasso, col = "red", xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.poly.income3, col = "green", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
plot(roc.lda_, col = "blue", add = TRUE, xlim = c(0, 0.3), ylim = c(0.7, 1.0))
legend("bottomright", legend = c("LASSO", "polyincome3", "LDA"), 
       col = c("red", "green", "blue"), 
       lty=1, lwd=1)

#fake<-train
#fake$Personal.Loan<-sample(fake$Personal.Loan,3500,replace=F)
#LDA.model.fake = lda(Personal.Loan ~ ., fake)
#LDA.model.fake

confusionMatrix(class.lasso, test$Personal.Loan)$overall[1]
confusionMatrix(class.poly.income3, test$Personal.Loan)$overall[1]
round((mean(predict(LDA.model,newdata=test)$class==test$Personal.Loan)),3)
```


