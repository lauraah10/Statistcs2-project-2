---
title: "LoanLogisticRegModel"
author: "Laura"
date: ""
output: "pdf_document"
---

```{r, setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, comment=NA) 
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Load Libraries
library(Hmisc)
library(gridExtra)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggthemes)
library(class)
library(caret)

```

# EDA
#### **Looking into the data**

```{r, include=FALSE}
PersonalLoan=read.csv("~/Documents/Statistics 2/StatsProject2/Statistcs2-project-2/Bank_Personal_Loan_Modelling.csv")

# 14 attributes
dim(PersonalLoan)[2]
print("There are 14 Columns")
# 5000 data size
nrow(PersonalLoan)
print("There 5000 entries")
# no duplicates
any(duplicated(PersonalLoan))
print("There are no duplicates")

#No missing values
print("No missing values")
(sapply(PersonalLoan, function(x) all_miss=sum(is.na(x))))

attach(PersonalLoan)
head(PersonalLoan)
```

#### **Statistics**

+ ID can be dropped since it is not a useful predictor and just a unique identifier and will affect the results of the model
+ Age mean is 45 years old, 23 has is the lowest and 67 is the highest. There seems to be a normal distribution.
+ ***There are negative values in Experience which is odd because there can't be negative  years of experience. This will be looked at next***.
+ The mean income is 73 while the median is 64 showing skewness which seems normal representation of society. The minimum income is 8,000 and the max is 224,000. These are common Salaries
+ ZIP.Code should not be numberic they should be changed to categorical. There are 467 distinct ZIP codes
+ There seems to be an equal distribution for families size 1,2,3,4. Each are compose of about 25%
+ The CCAVG, Average Spending per 1000 goes from 0 to 10,000, however the median is 1,5000. Here we can see that there are outliers. 
+ For Education, 41% have have up to highschool, 28% up to under grad studies and interestingly 30% have up to grad school. That seems like a reasonable distribution.
+ For mortgage we can see how skewed it is, the mean is 56.5 and the median is 0. Showing the extreme outliers. **This needs to be looked at**
+ For the target variable, personal loan, we can see quite a difference, 90% without a loan and only 10% with loan. This makes sense because not many people take loan from banks
+ Securities account also has a big difference where 90% does not have a security account while 10% does
+ **it would be interesting to see if this 10% is also the one with the loan**
+ For CD.Account (Ceritificate deposit) once again we see the 94% does not have it while 6% has it.
+ As for online (online banking capability), 40% doe not have it while 60% has it. That distribution is a little more balanced and makes sense.
+ As for Credit card 70% does not have it while 30% has it. 

-------------------------------------------------------------------------------------------------------

```{r, warning = F, echo=FALSE}
print(describe(PersonalLoan))
summary(PersonalLoan)
```


##### Looking into questions obtained in the statistical analysis

+ ***Looking at the entries with negative experience***
+ The 52 people with negative total experience are between 23 to 29 years old and salary median of 65,000. Sound like these could just young people that just started working. We can change their negative values to 1 since they have an income, thus are are working.

```{r, echo=FALSE}
library(dplyr)
#Verifying who are the people with negative experience 
summary(PersonalLoan %>% select (Age,Income,Personal.Loan) %>% filter(Experience<0) )

#Updating values
PersonalLoan$Experience[PersonalLoan$Experience<0]=1
```


# Extra plots
+ Not sure what this means....


```{r, echo=FALSE}
ggplot(PersonalLoan,aes(x=Income,y=Personal.Loan))+geom_point()+
  geom_smooth(method="loess",size=1)+
  ylim(-.2,1.2)
```

+ Setting categories as factors
```{r}
PersonalLoan$Personal.Loan<-factor(ifelse(PersonalLoan$Personal.Loan==1,1,0),levels=c(0,1))  #last level is the success

PersonalLoan$Securities.Account=as.factor(PersonalLoan$Securities.Account)
PersonalLoan$CD.Account =as.factor(PersonalLoan$CD.Account)
PersonalLoan$Online =as.factor(PersonalLoan$Online)
PersonalLoan$CreditCard =as.factor(PersonalLoan$CreditCard)
PersonalLoan$Family =as.factor(PersonalLoan$Family)
str(PersonalLoan)

#Droppingzip and ID as there are too many unique values and will affect the model
PersonalLoan=PersonalLoan %>% select(-ID)
PersonalLoan=PersonalLoan %>% select(-"ZIP.Code")

```

+ ***Checking mortgage distribution***
+ Mortgage may need to be logged as it is very skewed.


```{r, echo=FALSE}

a=PersonalLoan %>% ggplot(aes(x=(Mortgage), color="blue")) + geom_boxplot()+ theme_classic()+ theme(legend.position="none") + ggtitle("Distribution of Mortgage")

b=PersonalLoan %>% ggplot(aes(x=log(Mortgage), color="blue")) + geom_boxplot()+ theme_classic() +theme(legend.position="none")+ ggtitle("Distribution of Mortgage logged")
grid.arrange(a,b, ncol=2)
```

+ Creating another data set with Mortgage logged since logging did improve the distribution. The zero's were replaced to with 1 in order to not get infitiy when logging. Also, removing age since it has a 99% correlation with Experience, therefore only one is needed
```{r}
#Creating a new data set with the modified attributes
PersonalLoan2=mutate(PersonalLoan)
#Updating values
PersonalLoan2$Mortgage[PersonalLoan2$Mortgage==0]=1
PersonalLoan2$MortgageLogged=log(PersonalLoan2$Mortgage)
PersonalLoan2=PersonalLoan2 %>% select(-Mortgage)
PersonalLoan2=PersonalLoan2 %>% select(-Age)

```



#### **Relationships and correlations**

+ Experience and Age has a Correlation of 99%.Too high. However, they seem to have no relationship with Loan as both, Yes loan and no loan, have correlation of 0.99 
+ **Make a plot with just loan and experience  and experience and loan**
+ CCAvg and Income has a 64% correlations and it does seems to have a relationship with Loan since there is 0.62 with no loan and .02 with yes loan 
+ The rest of the explanatory variables do not seem to have relationship between each other

```{r echo=FALSE}
library(GGally)
ggpairs(PersonalLoan,columns = c(1,2,3,5,6,7,8),mapping=aes(colour=Personal.Loan))

library(corrplot)
numData=PersonalLoan %>% select(colnames(PersonalLoan)[!grepl('factor|logical|character',sapply(PersonalLoan,class))])
corrplot(cor(numData), type = "upper", order = "hclust", 
         tl.col = "black", sig.level = 0.05,insig = "blank")
```

#### **Checking realtionship between Loan (response variable) and the rest of the predictors**

##### Relationship present
+ ***Income***, the more income the more changes to get a loan 
+ ***CD.Account*** (certificate of deposit) seem to have a relationship with Personal Loan. Those with personal loan tend to have CD.Account more so than those with no CD.Account
+ ***Mortgage***, people high mortgages seem to ask for loans more so thatn those with lower mortgages
+ ***Personal education***, people with up to highschool tend do not get loans as much as does with an education of higher than highschool
+     !!**there seems to be relationship with loan and education but that of education 2 and 3 seem to be very close so maybe making 2 and 3 one single category would be more helpful**!!


##### Very small relationship
+ ***Security account*** and Personal Loan  seem to have slight relationship

##### No relationship with response
+ ***Online and Credit card*** don't seem to have a relationship

## Looking closer at each realationship to see if anything was missed

```{r, echo=FALSE, warning=FALSE}
library(GGally)
library(car) 
#ggpairs(numData, aes(alpha = 0.4))
#pairs(lifeExp[,-c(1,3)],col=Status)

par(mfrow=c(2,3))
plot(Personal.Loan~., data = PersonalLoan,col=c("pink","lightblue"))

```



```{r, include=FALSE}
# Looking deeper at relationship between Loan and Securities Account
# There actually is a relationship
#Loan vs securites
a=ggplot(PersonalLoan, aes(x=Securities.Account, fill=Personal.Loan)) + geom_bar(position="dodge")+theme(legend.position="none")+ ggtitle("Security account vs Loan")

b=ggplot(PersonalLoan, aes(x=Online, fill=Personal.Loan)) + geom_bar(position="dodge")+theme(legend.position="none")+ ggtitle("Online access vs Loan")

c=ggplot(PersonalLoan, aes(x=CreditCard, fill=Personal.Loan)) + geom_bar(position="dodge")+theme(legend.position="none")+ ggtitle("Credit Card vs Loan")

grid.arrange(a,b,c, ncol=2)

 
```


# Model: Objective 1
```{r}
# Splitting Data
set.seed(1234)
index<-sample(1:dim(PersonalLoan)[1],round(.70 * dim(PersonalLoan)[1]))
trainPL<-PersonalLoan[index,]
testPL<-PersonalLoan[-index,]
```

***Performing model with all variables and then another one with Stepwise***
+ With the full model with all attributes it showed that the only important were Income, Family,CCavg, Education,Securites.Account, CD.Account, Online, CreditCard

+ Once Stepwise was added to the full model it selected all of those that appeared as significant in the full model:Income, Family, CCAvg, Education, Securities.Account, CD.Account, Online, CreditCard. It also selected Experience but that one was not significant as we had seen in the EDA.


Here is the sumary of Stepwise

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(MASS)
library(tidyverse)
library(car)
simpleLG<-glm(Personal.Loan~.,family="binomial",data=PersonalLoan)


stepWiseAIC<-simpleLG %>% stepAIC(trace=FALSE, direction = "both")
summary(stepWiseAIC)
```

***Performing lasso using Cross validation to obtain the optimal penalty***
+ LASSO ended up choosing all attributes, not getting rid of any

Here is the output
```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(glmnet)
#Age Family Mortgage CD.Account0 CD.Account1 Experience CCAvg Online1 Income Education Securities.Account1
dat.train.x <- model.matrix(Personal.Loan~Age+Family+Mortgage+CD.Account-1+Experience+CCAvg-1+Online-1+ Income+Education+Securities.Account-1+CreditCard-1,trainPL)
dat.train.y<-trainPL[,8]

#cross validation
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")

#CV misclassification error rate is little below .1
#print("CV Error Rate:")
misE=cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#For final model predictions go ahead and refit lasso using entire  using the lowest penalty found
#data set
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)
coef(finalmodel)

finalmodel2<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=misE)
coef(finalmodel2)
#summary(finalmodel)
#Age, Family, Mortgage, CD.Account, Experience,CCAvg, Online, Income, Education, Securites.Account,CreditCard

```


***Predicting on models created***

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Predicting

#setting matrix for dummy for LASSO
dat.test.x<-model.matrix(Personal.Loan~Age+Family+Mortgage+CD.Account-1+Experience+CCAvg-1+ Personal.Loan-1+Online-1+ Income+Education+Securities.Account-1+CreditCard-1,testPL)

FullLG<-glm(Personal.Loan~.,family="binomial",data=trainPL)
fit.pred.full<-predict(FullLG,newdata=testPL,type="response")

#use model created and the test set with dummies to predict!
fit.pred.lasso <- predict(finalmodel, newx = dat.test.x, type = "response")

#use model created and the test set with dummies to predict!
fit.pred.lasso2 <- predict(finalmodel2, newx = dat.test.x, type = "response")

#Making predictions for stepwise as well for later
fit.pred.step<-predict(stepWiseAIC,newdata=testPL,type="response")

```

+ Using different threholds 
```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(caret)

ModelList=c()
Sensitivitylis=c()
Specificitylis=c()

adjusting_threashold <- function(cutoff) {
   print(paste("When setting the threashold to", cutoff))
   print("")
   class.full<-factor(ifelse(fit.pred.full>cutoff,1,0),levels=c(0,1))
   class.lasso<-factor(ifelse(fit.pred.lasso>cutoff,1,0),levels=c(0,1))
   class.step<-factor(ifelse(fit.pred.step>cutoff,1,0),levels=c(0,1))

  #Confusion Matrix for Lasso
  conf.full<-table(class.full,testPL$Personal.Loan)
  print("Confusion matrix for Model with all variables")
  print(conf.full)
  ModelList=append(ModelList,"Full Model")
  print("")
  print("Accuracy")
  print (mean(class.full==testPL$Personal.Loan))
  Sensitivitylis=append(Sensitivitylis,mean(class.full==testPL$Personal.Loan))
  print("Specificity")
  print(specificity(class.full, testPL$Personal.Loan)) 
  Specificitylis=append(Specificitylis,specificity(class.full, testPL$Personal.Loan))
  
      
  #Confusion Matrix for Lasso
  conf.lasso<-table(class.lasso,testPL$Personal.Loan)
  print("Confusion matrix for LASSO")
  print(conf.lasso)
  ModelList=append(ModelList,"Lasso Model")
  print("Accuracy")
  print (mean(class.lasso==testPL$Personal.Loan))
  Sensitivitylis=append(Sensitivitylis,mean(class.lasso==testPL$Personal.Loan))
  print("Specificity")
  print(specificity(class.lasso, testPL$Personal.Loan))
  Specificitylis=append(Specificitylis,specificity(class.lasso, testPL$Personal.Loan))
  
  #confusion Matrix for Stepwise
  conf.step<-table(class.step,testPL$Personal.Loan)
  print("Confusion matrix for Stepwise")
  ModelList=append(ModelList,"Stepwise Model")
  print(conf.step)
  print("Accuracy")
  print(mean(class.step==testPL$Personal.Loan))
  Sensitivitylis=append(Sensitivitylis,mean(class.step==testPL$Personal.Loan))
  print("Specificity")
  print(specificity(class.step, testPL$Personal.Loan))
  Specificitylis=append(Specificitylis,specificity(class.step, testPL$Personal.Loan))
  print("-----------------------------------")
  


}

adjusting_threashold(0.5)
adjusting_threashold(0.7)
adjusting_threashold(0.3)

```

```{r, include=FALSE}


#results_models=data.frame(ModelType=ModelList, Sensitivity=Sensitivitylis, Specificitylis=Specificitylis)

#results_models
```    

***Running ROC to compare models***
```{r, eccho=FALSE}
library(ROCR)
results.lasso<-prediction(fit.pred.lasso, testPL$Personal.Loan,label.ordering=c(0,1))
roc.lasso = performance(results.lasso, measure = "tpr", x.measure = "fpr")

results.lasso2<-prediction(fit.pred.lasso2, testPL$Personal.Loan,label.ordering=c(0,1))
roc.lasso2 = performance(results.lasso2, measure = "tpr", x.measure = "fpr")

results.step<-prediction(fit.pred.step, testPL$Personal.Loan,label.ordering=c(0,1))
roc.step = performance(results.step, measure = "tpr", x.measure = "fpr")

results.origin<-prediction(fit.pred.full,testPL$Personal.Loan,label.ordering=c(0,1))
roc.origin=performance(results.origin,measure = "tpr", x.measure = "fpr")

```

```{r, echo=FALSE}
plot(roc.lasso)
plot(roc.lasso2, col="red", add=TRUE)
plot(roc.step,col="orange", add = TRUE)
plot(roc.origin,col="blue",add=TRUE)
legend("bottomright",legend=c("Lasso", "Lasso w Higher Penalty","Stepwise","All Variables"),col=c("black","red","orange","blue"),lty=1,lwd=1)
abline(a=0, b= 1)
```


+ The best model seemed to be the Stepwise 
```{r}
plot(roc.step,colorize = TRUE)
abline(a=0, b= 1)
      
```


# Conclusion from Part 1
+ The best model was step setting the threshold to 0.3
it gave an sensitivity of 94 and specificity of 72
+ Due to the imbalance of amount of people with loan and without loan we do see we do see that the model favors no loan due to it but 72 compared to the 55 specificity was a great increase. This model is about trying to predict those who will say yes to Loan therefore Specificity is important. 
+ The attributes found useful were : Income, Family,CCavg, Education,Securites.Account, CD.Account, Online, CreditCard
+ The threshold was set to 0.3 and it lead to a Sensitivity of 0.96 and specificy of 0.71
+ These were variables seen in the EDA as related to the loan.
+ Coefficients results:
For every unit increase in income the odd of getting a loan are  e^1.06 times higher
For every unit increase in Family the odd of getting a loan are  e^0.698209 times higher
For every unit increase in CCAvg the odd of getting a loan are  e^0.120635 times higher
For every unit increase in  Education  the odd of getting a loan are  e^1.713690 times higher
For every unit increase in Securities.Account 1  the odd of getting a loan are  e^-0.937183 times less likely
For every unit increase in CD.Account1  the odd of getting a loan are  e^3.840892 times higher
For every unit increase in Online1 the odd of getting a loan are  e^-0.673230 times less likely
For every unit increase in CreditCard1 the odd of getting a loan are  e^ -1.122701 times higher


```{r}
summary(stepWiseAIC)
(coef(stepWiseAIC))
AIC(stepWiseAIC)
# let's predict the same data: use type response to have probability as resulthere you decide the cutoff and put as factor, in one line
pred_ <- as.factor(ifelse(predict(stepWiseAIC, testPL, type="response")>0.3,1,0))
# here we go!
confusionMatrix(pred_, as.factor(testPL$Personal.Loan))

AIC(stepWiseAIC)
```





## EXTRA  code that has been commented out
###### Re-run all models but removing age and Logging mortgage


```{r, include=FALSE}
set.seed(1234)
index<-sample(1:dim(PersonalLoan2)[1],round(.70 * dim(PersonalLoan2)[1]))
trainPL<-PersonalLoan2[index,]
testPL<-PersonalLoan2[-index,]
```


```{r, include=FALSE, warning=FALSE, message=FALSE}
# Stepwise selected same as the model without the log mortgage and AGE:Experience, income, family, CCAvg, Education, Securities.Account1,CD.Account1, Online1,CreditCard1


#running  model with all variables
simpleLG<-glm(Personal.Loan~.,family="binomial",data=PersonalLoan2)

stepWiseAIC<-simpleLG %>% stepAIC(trace=FALSE)
summary(stepWiseAIC)


```



```{r, include=FALSE, warning=FALSE, message=FALSE}
#***When running Lasso it also once again picked all variables


#Age Family Mortgage CD.Account0 CD.Account1 Experience CCAvg Online1 Income Education Securities.Account1
dat.train.x <- model.matrix(Personal.Loan~Family+MortgageLogged+CD.Account-1+CCAvg-1+Online-1+ Income+Education+Securities.Account-1+CreditCard-1,trainPL)
dat.train.y<-trainPL[,6]

#cross validation
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")

#CV misclassification error rate is little below .1
print("CV Error Rate:")
cvfit$cvm[which(cvfit$lambda==cvfit$lambda.min)]

#For final model predictions go ahead and refit lasso using entire  using the lowest penalty found
#data set
finalmodel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)
coef(finalmodel)


#summary(finalmodel)
#Age, Family, Mortgage, CD.Account, Experience,CCAvg, Online, Income, Education, Securites.Account,CreditCard

```

```{r, include=FALSE, warning=FALSE, message=FALSE}
#prdicting
#setting dummies for the test set
dat.test.x<-model.matrix(Personal.Loan~Family+MortgageLogged+CD.Account-1+CCAvg-1+Online-1+ Income+Education+Securities.Account-1+CreditCard-1,testPL)


FullLG<-glm(Personal.Loan~.,family="binomial",data=trainPL)
fit.pred.full<-predict(FullLG,newdata=testPL,type="response")
#use model created and the test set with dummies to predict!
fit.pred.lasso <- predict(finalmodel, newx = dat.test.x, type = "response")
#Making predictions for stepwise as well for later
fit.pred.step<-predict(stepWiseAIC,newdata=testPL,type="response")

```



```{r, include=FALSE, warning=FALSE, message=FALSE}
#+ Printing results for different threshold 

#The best result was setting threashold to 0.3 with an Accuracy 0.9433333 and Specificity of 0.7152318



ModelList=c()
Sensitivitylis=c()
Specificitylis=c()

cutoff=.5
adjusting_threashold <- function(cutoff) {
   print(paste("When setting the threashold to", cutoff))
   print("")
   class.full<-factor(ifelse(fit.pred.full>cutoff,1,0),levels=c(0,1))
   class.lasso<-factor(ifelse(fit.pred.lasso>cutoff,1,0),levels=c(0,1))
   class.step<-factor(ifelse(fit.pred.step>cutoff,1,0),levels=c(0,1))

  #Confusion Matrix for Lasso
  conf.full<-table(class.full,testPL$Personal.Loan)
  print("Confusion matrix for Model with all variables")
  print(conf.full)
  ModelList=append(ModelList,"Full Model")
  print("")
  print("Accuracy")
  print (mean(class.full==testPL$Personal.Loan))
  Sensitivitylis=append(Sensitivitylis,mean(class.full==testPL$Personal.Loan))
  print("Specificity")
  print(specificity(class.full, testPL$Personal.Loan)) 
  Specificitylis=append(Specificitylis,specificity(class.full, testPL$Personal.Loan))
  
      
  #Confusion Matrix for Lasso
  conf.lasso<-table(class.lasso,testPL$Personal.Loan)
  print("Confusion matrix for LASSO")
  print(conf.lasso)
  ModelList=append(ModelList,"Lasso Model")
  print("Accuracy")
  print (mean(class.lasso==testPL$Personal.Loan))
  Sensitivitylis=append(Sensitivitylis,mean(class.lasso==testPL$Personal.Loan))
  print("Specificity")
  print(specificity(class.lasso, testPL$Personal.Loan))
  Specificitylis=append(Specificitylis,specificity(class.lasso, testPL$Personal.Loan))
  
  #confusion Matrix for Stepwise
  conf.step<-table(class.step,testPL$Personal.Loan)
  print("Confusion matrix for Stepwise")
  ModelList=append(ModelList,"Stepwise Model")
  print(conf.step)
  print("Accuracy")
  print(mean(class.step==testPL$Personal.Loan))
  Sensitivitylis=append(Sensitivitylis,mean(class.step==testPL$Personal.Loan))
  print("Specificity")
  print(specificity(class.step, testPL$Personal.Loan))
  Specificitylis=append(Specificitylis,specificity(class.step, testPL$Personal.Loan))
  print("-----------------------------------")
  


}

adjusting_threashold(0.5)
adjusting_threashold(0.9)
adjusting_threashold(0.3)

```   


```{r, include=FALSE, warning=FALSE, message=FALSE}
library(ROCR)
results.lasso<-prediction(fit.pred.lasso, testPL$Personal.Loan,label.ordering=c(0,1))
roc.lasso = performance(results.lasso, measure = "tpr", x.measure = "fpr")

results.step<-prediction(fit.pred.step, testPL$Personal.Loan,label.ordering=c(0,1))
roc.step = performance(results.step, measure = "tpr", x.measure = "fpr")

results.origin<-prediction(fit.pred.full,testPL$Personal.Loan,label.ordering=c(0,1))
roc.origin=performance(results.origin,measure = "tpr", x.measure = "fpr")

```

```{r, include=FALSE}
#+ The best model once again was Stepwise but the results of the first set of model

plot(roc.lasso)
plot(roc.step,col="orange", add = TRUE)
plot(roc.origin,col="blue",add=TRUE)
legend("bottomright",legend=c("Lasso","Stepwise","All Variables"),col=c("black","orange","blue"),lty=1,lwd=1)
abline(a=0, b= 1)
```
```{r, include=FALSE}
plot(roc.step,colorize = TRUE)
abline(a=0, b= 1)
      
```



